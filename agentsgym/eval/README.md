Our evaluation process consists of two primary types. The first is a question-answering (QA) style evaluation, similar to benchmarks like GSM8K and MLLU. For this type, we utilize a readily available, off-the-shelf library. The goal is to measure how our Agents training impacts LLM performance on other tasks.

The second type is our custom multi-turn evaluation. For this, we import our environments and directly measure performance within them.
